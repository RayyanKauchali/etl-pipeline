version: '3.8'

services:
  # Airflow metadata DB
  airflow-postgres:
    image: postgres:15
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_airflow_db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 10s
      retries: 10

  # Redis (optional for Celery; required by some setups)
  redis:
    image: redis:7
    container_name: airflow-redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping || exit 1"]
      interval: 10s
      retries: 5

  # Airflow (webserver + scheduler in one container for simple dev)
  airflow:
    image: apache/airflow:2.6.3
    container_name: airflow
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_started
      minio:
        condition: service_started
      pg_etl:
        condition: service_started
    environment:
      # Core config
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: "fernetkeyplaceholderchangeme"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      # Web auth (basic)
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth"
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./:/opt/airflow/project 
      - ./plugins:/opt/airflow/plugins
      - ./etl_tasks.py:/opt/airflow/etl_tasks.py
      - ./requirements.txt:/requirements.txt
    command: >
      bash -c "
        pip install --no-cache-dir -r /requirements.txt || true &&
        airflow db upgrade &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true &&
        airflow scheduler & airflow webserver
      "
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "airflow db check || true"]
      interval: 30s
      retries: 3

  # MinIO for object storage (S3-compatible)
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ':9001'
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:9000 || exit 1"]
      interval: 15s
      retries: 5

  # Postgres for ETL target (where cleaned tables are stored)
  pg_etl:
    image: postgres:15
    container_name: pg_etl
    environment:
      POSTGRES_USER: etl_user
      POSTGRES_PASSWORD: etl_pass
      POSTGRES_DB: analytics_db
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U etl_user -d analytics_db"]
      interval: 10s
      retries: 10

  # Dashboard Service (Streamlit)
  dashboard:
    build: ./dashboard
    container_name: dashboard
    ports:
      - "8501:8501"
    depends_on:
      pg_etl:
        condition: service_healthy
    environment:
      - DB_HOST=pg_etl
      - DB_NAME=analytics_db
      - DB_USER=etl_user
      - DB_PASS=etl_pass
    volumes:
      - ./dashboard:/app
    networks:
      - default

volumes:
  postgres_airflow_db:
  minio_data:
  pgdata:
